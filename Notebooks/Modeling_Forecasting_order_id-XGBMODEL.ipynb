{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import darts\n",
    "from darts import TimeSeries\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.metrics import mean_squared_log_error \n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "from darts.dataprocessing.transformers.scaler import Scaler\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helping Functions \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter(df):\n",
    "    os.makedirs('../plots/Iteration_03',exist_ok=True)\n",
    "    saturday_Df = df[df['day_of_week']==5]\n",
    "    sunday_Df = df[df['day_of_week']==6]\n",
    "    friday_Df = df[df['day_of_week']==4]\n",
    "    thursday_Df = df[df['day_of_week']==3]\n",
    "    wednesday_Df = df[df['day_of_week']==2]\n",
    "    Tuesday_Df = df[df['day_of_week']==1]\n",
    "    monday_Df = df[df['day_of_week']==0]\n",
    "    \n",
    "    jan_Df = df[df['month']==1]\n",
    "    feb_Df = df[df['month']==2]\n",
    "    march_Df = df[df['month']==3]\n",
    "    april_Df = df[df['month']==4]\n",
    "    may_Df = df[df['month']==5]\n",
    "    june_Df = df[df['month']==6]\n",
    "    july_Df = df[df['month']==7]\n",
    "    aug_Df = df[df['month']==8]\n",
    "    sept_Df = df[df['month']==9]\n",
    "    oct_Df = df[df['month']==10]\n",
    "    Nov_Df = df[df['month']==11]\n",
    "    decem_Df = df[df['month']==12]\n",
    "    \n",
    "    \n",
    "    fig = make_subplots()\n",
    "                        \n",
    "    \n",
    "    fig.add_trace(go.Scatter(x=df['date'], y=df['order_id'], mode='markers+lines',name='Quantity'),row=1,col=1)\n",
    "    fig.add_trace(go.Scatter(x=saturday_Df['date'], y=saturday_Df['order_id'], mode='markers',name='-Saturday-Quantity'),row=1,col=1)\n",
    "    fig.add_trace(go.Scatter(x=sunday_Df['date'], y=sunday_Df['order_id'], mode='markers',name='-Sunday-Quantity'),row=1,col=1)\n",
    "    fig.add_trace(go.Scatter(x=friday_Df['date'], y=friday_Df['order_id'], mode='markers',name='-friday-Quantity'),row=1,col=1)\n",
    "    fig.add_trace(go.Scatter(x=thursday_Df['date'], y=thursday_Df['order_id'], mode='markers',name='-Thursday-Quantity'),row=1,col=1)\n",
    "    fig.add_trace(go.Scatter(x=wednesday_Df['date'], y=wednesday_Df['order_id'], mode='markers',name='-Wednesday-Quantity'),row=1,col=1)\n",
    "    fig.add_trace(go.Scatter(x=Tuesday_Df['date'], y=Tuesday_Df['order_id'], mode='markers',name='-Tuesday-Quantity'),row=1,col=1)\n",
    "    fig.add_trace(go.Scatter(x=monday_Df['date'], y=monday_Df['order_id'], mode='markers',name='-Monday-Quantity'),row=1,col=1)\n",
    "    \n",
    "    fig.add_trace(go.Scatter(x=jan_Df['date'], y=jan_Df['order_id'], mode='markers+lines',name='-Jan-Quantity'),row=1,col=1)\n",
    "    fig.add_trace(go.Scatter(x=feb_Df['date'], y=feb_Df['order_id'], mode='markers+lines',name='-Feb-Quantity'),row=1,col=1)\n",
    "    fig.add_trace(go.Scatter(x=march_Df['date'], y=march_Df['order_id'], mode='markers+lines',name='-March-Quantity'),row=1,col=1)\n",
    "    fig.add_trace(go.Scatter(x=april_Df['date'], y=april_Df['order_id'], mode='markers+lines',name='-April-Quantity'),row=1,col=1)\n",
    "    fig.add_trace(go.Scatter(x=may_Df['date'], y=may_Df['order_id'], mode='markers+lines',name='-May-Quantity'),row=1,col=1)\n",
    "    fig.add_trace(go.Scatter(x=june_Df['date'], y=june_Df['order_id'], mode='markers+lines',name='-June-Quantity'),row=1,col=1)\n",
    "    fig.add_trace(go.Scatter(x=july_Df['date'], y=july_Df['order_id'], mode='markers+lines',name='-july-Quantity'),row=1,col=1)\n",
    "    fig.add_trace(go.Scatter(x=aug_Df['date'], y=aug_Df['order_id'], mode='markers+lines',name='-Aug-Quantity'),row=1,col=1)\n",
    "    fig.add_trace(go.Scatter(x=sept_Df['date'], y=sept_Df['order_id'], mode='markers+lines',name='-Sept-Quantity'),row=1,col=1)\n",
    "    fig.add_trace(go.Scatter(x=Nov_Df['date'], y=Nov_Df['order_id'], mode='markers+lines',name='-Nov-Quantity'),row=1,col=1)\n",
    "    fig.add_trace(go.Scatter(x=oct_Df['date'], y=oct_Df['order_id'], mode='markers+lines',name='-Oct-Quantity'),row=1,col=1)\n",
    "    fig.add_trace(go.Scatter(x=decem_Df['date'], y=decem_Df['order_id'], mode='markers+lines',name='-Decem-Quantity'),row=1,col=1)\n",
    "    \n",
    "\n",
    "\n",
    "    fig.update_layout(\n",
    "        title='Scatter Plot of Order ID',\n",
    "        height=600,\n",
    "        width=1800,\n",
    "        font_size=14\n",
    "    )\n",
    "    fig.update_yaxes(title_text='Quantity', row=1, col=1)\n",
    "    fig.update_yaxes(title_text='Revenue', row=2, col=1)\n",
    "    fig.show()\n",
    "    fig.write_html(f'../plots/Iteration_03/all_data.html')\n",
    "\n",
    "def calculate_smape(actual, predicted):\n",
    "    \"\"\"\n",
    "    Calculate Symmetric Mean Absolute Percentage Error (SMAPE) given actual and predicted values.\n",
    "\n",
    "    Parameters:\n",
    "    actual (list or array): The actual (true) values.\n",
    "    predicted (list or array): The predicted values.\n",
    "\n",
    "    Returns:\n",
    "    smape (float): The SMAPE value.\n",
    "    \"\"\"\n",
    "    n = len(actual)\n",
    "    sum_smape = sum(2 * abs(a - p) / (abs(a) + abs(p)) for a, p in zip(actual, predicted))\n",
    "    smape = (1 / n) * sum_smape * 100\n",
    "    return smape\n",
    "\n",
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.metrics import mean_squared_log_error \n",
    "\n",
    "def calculate_metrics(actual, predicted):\n",
    "    # Convert inputs to numpy arrays for easier calculations\n",
    "    smape = calculate_smape(actual, predicted)\n",
    "    r2 = r2_score(actual, predicted)\n",
    "\n",
    "    medae = median_absolute_error(actual, predicted)\n",
    "\n",
    "    # Mean Squared Logarithmic Error (MSLE)\n",
    "    msle = mean_squared_log_error(actual, predicted)\n",
    "    \n",
    "    actual = np.array(actual)\n",
    "    predicted = np.array(predicted)\n",
    "    \n",
    "    # Calculate individual metrics\n",
    "    mae = np.mean(np.abs(predicted - actual))\n",
    "    rmse = np.sqrt(np.mean((predicted - actual) ** 2))\n",
    "    mape = np.mean(np.abs((predicted - actual) / actual)) * 100\n",
    "    mse = np.mean((predicted - actual) ** 2)\n",
    "    \n",
    "    metrics = {\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'MAPE': mape,\n",
    "        'MSE': mse,\n",
    "        'SMAPE':smape,\n",
    "        'R2':r2,\n",
    "        'MEDEA':medae,\n",
    "        'MSLE':msle,\n",
    "        \n",
    "    }\n",
    "    \n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('../processedData/Iteration_03', exist_ok=True)\n",
    "\n",
    "fileName = '../RawData/Sales Forecast_NEW2.xlsx'\n",
    "df = pd.read_excel(fileName,sheet_name='NEW_DATA')\n",
    "df['date'] = pd.to_datetime(df['date'],format='%Y-%m-%d')\n",
    "df.sort_values(['date'],inplace=True)\n",
    "df.reset_index(inplace=True,drop=True)\n",
    "df.to_csv('../processedData/Iteration_03/sorted_Sales_Forecast_dataset.csv',index=False)\n",
    "df =  df[['date','order_id']]\n",
    "df.to_csv('../processedData/Iteration_03/date_order_sales_forecast_dataset.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.groupby('date')['order_id'].sum().reset_index()\n",
    "df.to_csv('../processedData/Iteration_03/date_order_id_sales_forecast_cleaned.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'] = df['date'].dt.year\n",
    "df['day_of_month'] = df['date'].dt.day\n",
    "df['month'] = df['date'].dt.month\n",
    "df['day_of_week'] = df['date'].dt.day_of_week\n",
    "df['day_name'] = df['date'].dt.strftime('%A')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[:-30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spliting Data into Training & Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts import TimeSeries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming df is your DataFrame containing daily data\n",
    "series = TimeSeries.from_dataframe(df, \"date\", \"order_id\", freq='1D', fill_missing_dates=True, fillna_value=0)\n",
    "\n",
    "\n",
    "split_point = pd.Timestamp('2023-04-30')\n",
    "\n",
    "train_series, test_series = series.split_after(split_point)\n",
    "\n",
    "# Set the figure size and style\n",
    "plt.figure(figsize=(18, 6))\n",
    "# Plot the training and testing data\n",
    "train_series.plot(label='Training Data', color='blue', linewidth=1.5, marker='o')\n",
    "test_series.plot(label='Testing Data', color='orange', linewidth=1.5, marker='o')\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Training and Testing Data')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Global DGV NS Visits')\n",
    "\n",
    "# Add grid lines\n",
    "plt.grid(True)\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGB Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Define your XGBModel class if not already defined\n",
    "# class XGBModel:\n",
    "#     def __init__(self, lags, output_chunk_length, likelihood, quantiles, random_state, multi_models, use_static_covariates):\n",
    "#         # Your initialization code here\n",
    "#         pass\n",
    "#     def fit(self, train_series):\n",
    "#         # Your fitting logic here\n",
    "#         pass\n",
    "        \n",
    "#     def predict(self, horizon):\n",
    "#         # Your prediction logic here\n",
    "#         pass\n",
    "#         return predicted_series\n",
    "\n",
    "# def plot_and_save(title, xgb_model, test_series, output_chunk_length):\n",
    "#     horizan = output_chunk_length\n",
    "#     test_series_ = test_series[0:horizan]\n",
    "#     plt.figure(figsize=(18, 6))\n",
    "\n",
    "#     forcast_xgbmodel = xgb_model.predict(horizan)\n",
    "#     forcast_xgbmodel.plot(marker='o', label='predicted')\n",
    "#     test_series_.plot(marker='o', label='Actual/Ground truth')\n",
    "#     plt.title(f'Ground truth vs predicted : {title}')\n",
    "#     plt.xlabel('Date')\n",
    "#     plt.ylabel('Order Number')\n",
    "#     plt.xticks(forcast_xgbmodel.time_index, forcast_xgbmodel.time_index.strftime('%Y-%m-%d'), rotation=90)\n",
    "#     plt.grid(True)\n",
    "#     plt.legend()\n",
    "#     plot_filename = f\"../plots/XgbModelsGridsearch/{title}.png\"\n",
    "#     plt.savefig(plot_filename)\n",
    "#     plt.close()\n",
    "\n",
    "# def perform_grid_search(parameters, train_series, test_series):\n",
    "#     best_mse = float('inf')\n",
    "#     best_params = {}\n",
    "    \n",
    "#     for lags in parameters['lags']:\n",
    "#         for output_chunk_length in parameters['output_chunk_length']:\n",
    "#             for likelihood in parameters['likelihood']:\n",
    "#                 for quantiles in parameters['quantiles']:\n",
    "#                     for multi_models in parameters['multi_models']:\n",
    "#                         for use_static_covariates in parameters['use_static_covariates']:\n",
    "#                             title = f\"Lags-{lags}-likelihood-{likelihood}-quantiles-{quantiles}-multi_models-{multi_models}-use_static_covariates-{use_static_covariates}-output_length-{output_chunk_length}\"\n",
    "#                             try:\n",
    "#                                 print(f'Parameters:', title)\n",
    "#                                 xgb_model = XGBModel(lags=lags, \n",
    "#                                                     output_chunk_length=output_chunk_length, \n",
    "#                                                     likelihood=likelihood, \n",
    "#                                                     quantiles=quantiles, \n",
    "#                                                     random_state=199, \n",
    "#                                                     multi_models=multi_models, \n",
    "#                                                     use_static_covariates=use_static_covariates)\n",
    "\n",
    "#                                 xgb_model.fit(train_series)\n",
    "                                \n",
    "#                                 plot_and_save(title, xgb_model, test_series, output_chunk_length)\n",
    "\n",
    "#                                 predicted_values = np.array(forcast_xgbmodel.values().flatten())\n",
    "#                                 actual_values = np.array(test_series_.values().flatten())\n",
    "\n",
    "#                                 mse = np.mean((predicted_values - actual_values) ** 2)\n",
    "\n",
    "#                                 if mse < best_mse:\n",
    "#                                     best_mse = mse\n",
    "#                                     best_params = {\n",
    "#                                         'lags': lags,\n",
    "#                                         'output_chunk_length': output_chunk_length,\n",
    "#                                         'likelihood': likelihood,\n",
    "#                                         'quantiles': quantiles,\n",
    "#                                         'multi_models': multi_models,\n",
    "#                                         'use_static_covariates': use_static_covariates\n",
    "#                                     }\n",
    "#                                     best_params_df = pd.DataFrame.from_dict([best_params])\n",
    "#                                     best_params_df.to_csv(f'../BestParams/best_params_df_{title}.csv')\n",
    "#                             except Exception as e:\n",
    "#                                 print('Iteration : ', title)\n",
    "#                                 print('Exception has occurred in iteration ', e)\n",
    "    \n",
    "#     return best_params, best_mse\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     pass\n",
    "#     # parameters = {\n",
    "#     #     'lags': [10, 20, 30, 40, 50, 60, 70, 80],\n",
    "#     #     'output_chunk_length': [10, 20, 30, 40, 50, 60, 90],\n",
    "#     #     'likelihood': ['poisson', 'quantile'],\n",
    "#     #     'quantiles': [[0.2, 0.5, 0.75, 0.9], [0.5, 0.75]],\n",
    "#     #     'multi_models': [True, False],\n",
    "#     #     'use_static_covariates': [True, False]\n",
    "#     # }\n",
    "\n",
    "#     # # Initialize train_series and test_series\n",
    "#     # train_series = ...\n",
    "#     # test_series = ...\n",
    "    \n",
    "#     # best_params, best_mse = perform_grid_search(parameters, train_series, test_series)\n",
    "\n",
    "#     # print(\"Best Parameters:\", best_params)\n",
    "#     # print(\"Best MSE:\", best_mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGB Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts.models.forecasting.xgboost import  XGBModel\n",
    "xgb_model= XGBModel(lags=30, \n",
    "                    output_chunk_length=90, \n",
    "                    # add_encoders={\n",
    "                    #     # 'cycli0c': {'future': ['month']},\n",
    "                    #     'datetime_attribute': {'future': ['hour', 'dayofweek']},\n",
    "                    #     # 'position': {'future': ['relative']},\n",
    "                    #     # 'custom': {'future': [lambda idx: (idx.year - 2013) / 50]},\n",
    "                    #     'transformer': Scaler()\n",
    "                    # }, \n",
    "                    likelihood='poisson', \n",
    "                    quantiles=[0.2, 0.5, 0.75, 0.9], \n",
    "                    random_state=199, \n",
    "                    multi_models=True, \n",
    "                    use_static_covariates=True)\n",
    "\n",
    "xgb_model.fit(train_series)\n",
    "\n",
    "horizan = 30*4\n",
    "\n",
    "test_series_ = test_series[0:horizan]\n",
    "plt.figure(figsize=(18, 6))\n",
    "\n",
    "forcast_arima = xgb_model.predict(horizan)\n",
    "xgb_model.predict(horizan).plot(marker='o',label='predicted')\n",
    "test_series_.plot(marker='o',label='Actual/Ground truth')\n",
    "# Add title and labels\n",
    "plt.title('Ground truth vs predicted')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Order Number')\n",
    "plt.xticks(forcast_arima.time_index, forcast_arima.time_index.strftime('%Y-%m-%d'), rotation=90)\n",
    "\n",
    "# Add grid lines\n",
    "plt.grid(True)\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Function to predict and evaluate\n",
    "def predict_and_evaluate(window_size, prediction_horizon, slide_step, test_series, model,result_plot_path ):\n",
    "    num_predictions = len(test_series) - window_size - prediction_horizon + 1\n",
    "    \n",
    "    meta_information_evaluation = {\n",
    "        'Iterations': [],\n",
    "        'MAE': [],\n",
    "        'RMSE': [],\n",
    "        'MAPE': [],\n",
    "        'MSE': [],\n",
    "        'SMAPE':[],\n",
    "        'R2':[],\n",
    "        'MEDEA':[],\n",
    "        'MSLE':[],\n",
    "        'input_window_size': [],\n",
    "        'horizon': [],\n",
    "        'stride': []\n",
    "    }\n",
    "    try:\n",
    "        for i in tqdm(range(0, num_predictions, slide_step)):\n",
    "            input_window = test_series[i:i + window_size]\n",
    "            ground_truth = test_series[i + window_size:i + window_size + prediction_horizon]\n",
    "            forecast = model.predict(n=prediction_horizon, series=input_window)\n",
    "            actual = ground_truth.values().flatten().tolist()\n",
    "            \n",
    "            predicted = forecast.values().flatten().tolist()\n",
    "            metrics = calculate_metrics(actual, predicted)\n",
    "            \n",
    "            meta_information_evaluation['Iterations'].append(i)\n",
    "            meta_information_evaluation['MAE'].append(metrics['MAE'])\n",
    "            meta_information_evaluation['RMSE'].append(metrics['RMSE'])\n",
    "            meta_information_evaluation['MAPE'].append(metrics['MAPE'])\n",
    "            meta_information_evaluation['MSE'].append(metrics['MSE'])\n",
    "            meta_information_evaluation['input_window_size'].append(window_size)\n",
    "            meta_information_evaluation['horizon'].append(prediction_horizon)\n",
    "            meta_information_evaluation['stride'].append(slide_step)\n",
    "            \n",
    "            meta_information_evaluation['SMAPE'].append(metrics['SMAPE'])\n",
    "            meta_information_evaluation['R2'].append(metrics['R2'])\n",
    "            meta_information_evaluation['MEDEA'].append(metrics['MEDEA'])\n",
    "            meta_information_evaluation['MSLE'].append(metrics['MSLE'])\n",
    "        \n",
    "            bypass_information = {\n",
    "                'slide_step':slide_step,\n",
    "                'window_size':window_size,\n",
    "                'horizon':prediction_horizon,            \n",
    "            }\n",
    "            create_plots(input_window,forecast,ground_truth,result_plot_path,bypass_information,metrics)\n",
    "\n",
    "        evalaution_df = pd.DataFrame.from_dict(meta_information_evaluation)\n",
    "        \n",
    "        return evalaution_df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print('Error Occurred in fuction predict_and_evaluate():', e)\n",
    "        evalaution_df = pd.DataFrame.from_dict(meta_information_evaluation)\n",
    "        \n",
    "        return evalaution_df\n",
    "\n",
    "# Function to create plots\n",
    "\n",
    "# Function to create plots\n",
    "def create_plots(input_window, forecast, ground_truth,result_plot_path,bypass_information,metrics):\n",
    "    \n",
    "    plt.figure(figsize=(30, 10))\n",
    "    input_window.plot(label='Input Data', marker='o')\n",
    "    forecast.plot(label='Predicted', marker='o')\n",
    "    ground_truth.plot(label='Ground Truth', marker='o')\n",
    "    \n",
    "    combined_time_index = input_window.time_index.append(forecast.time_index).append(ground_truth.time_index)\n",
    "    starting_date_of_input_data = input_window.time_index[0].strftime(\"%Y-%m-%d\")\n",
    "    ending_date_of_input_data = input_window.time_index[-1].strftime(\"%Y-%m-%d\")\n",
    "    starting_date_predicted = forecast.time_index[0].strftime(\"%Y-%m-%d\")\n",
    "    ending_date_of_predicted = forecast.time_index[-1].strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    smape = np.round(metrics['SMAPE'],2)\n",
    "    \n",
    "    cms_prediction = int(np.sum(forecast.values().flatten().tolist()))\n",
    "    cms_actual = int(np.sum(ground_truth.values().flatten().tolist()))\n",
    "    \n",
    "\n",
    "    plt.xticks(combined_time_index, combined_time_index.strftime('%Y-%m-%d'), rotation=90)\n",
    "    plt.title(f\"Results of Input Data from {starting_date_of_input_data} to {ending_date_of_input_data} & Evaluation on from {starting_date_predicted} to {ending_date_of_predicted}\\nSmape : {smape}\\n Total Number of Orders in Actual : {cms_actual}\\n Total Number of Orders in prediction : {cms_prediction}\", fontsize=16)\n",
    "    plt.ylabel('Number of Orders', fontsize=14)\n",
    "    plt.xlabel('Dates', fontsize=14)\n",
    "    plt.legend()\n",
    "    \n",
    "    plot_filename = f\"{result_plot_path}/{bypass_information['window_size']}_{bypass_information['horizon']}_{bypass_information['slide_step']}.png\"\n",
    "    plt.savefig(plot_filename)\n",
    "    plt.close()\n",
    "    # plt.show()\n",
    "    \n",
    "def model_evaluation(model_name,model_object,test_series,FileName):\n",
    "    \n",
    "    result_path = f'../ProcessedData/Results/{model_name}/{FileName}'\n",
    "    result_plot_path = f'../ProcessedData/Results/{model_name}/{FileName}/{model_name}_Plots'\n",
    "    os.makedirs(result_path,exist_ok=True)\n",
    "    os.makedirs(result_plot_path,exist_ok=True)\n",
    "\n",
    "        # Set your parameters\n",
    "    window_sizes = [30, 45, 60]\n",
    "    prediction_horizons = [30,54,40,25]\n",
    "    slide_steps = [2,5, 8, 15]\n",
    "\n",
    "\n",
    "    test_series = test_series\n",
    "    model = model_object\n",
    "\n",
    "    for window_size in window_sizes:\n",
    "        for prediction_horizon in prediction_horizons:\n",
    "            for slide_step in slide_steps:\n",
    "                print(f'Iteration : Window size : {window_size} Horizan: {prediction_horizon}, Stride : {slide_step}')\n",
    "                evaluation_df = predict_and_evaluate(window_size, prediction_horizon, slide_step, test_series, model,result_plot_path)\n",
    "                evaluation_df.to_csv(f'{result_path}/window_size_{window_size}_horizon_{prediction_horizon}_stride_{slide_step}.csv', index=False)\n",
    "                \n",
    "                print(f'Window_size_{window_size}_prediction_horizon_{prediction_horizon}_slide_step_{slide_step} - Evaluation completed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration : Window size : 30 Horizan: 30, Stride : 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:10<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window_size_30_prediction_horizon_30_slide_step_2 - Evaluation completed.\n",
      "Iteration : Window size : 30 Horizan: 30, Stride : 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window_size_30_prediction_horizon_30_slide_step_5 - Evaluation completed.\n",
      "Iteration : Window size : 30 Horizan: 30, Stride : 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:03<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window_size_30_prediction_horizon_30_slide_step_8 - Evaluation completed.\n",
      "Iteration : Window size : 30 Horizan: 30, Stride : 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window_size_30_prediction_horizon_30_slide_step_15 - Evaluation completed.\n",
      "Iteration : Window size : 30 Horizan: 54, Stride : 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window_size_30_prediction_horizon_54_slide_step_2 - Evaluation completed.\n",
      "Iteration : Window size : 30 Horizan: 54, Stride : 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "model_name = 'XGBMODEL'\n",
    "FileName = 'xgbmodel'\n",
    "model_object = xgb_model\n",
    "test_series = test_series \n",
    "model_evaluation(model_name,model_object,test_series,FileName)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "def aggregate_evaluation_results(file_pattern):\n",
    "    eval_dict = {\n",
    "        'window_size': [],\n",
    "        'horizan': [],\n",
    "        'stride': [],\n",
    "        'AVG_MAE': [],\n",
    "        'AVG_MSE': [],\n",
    "        'AVG_RMSE': [],\n",
    "        'AVG_MAPE': [],\n",
    "        'AVG_SMAPE':[],\n",
    "        'AVG_R2': [],\n",
    "        'AVG_MEDEA':[],\n",
    "        'AVG_MSLE' :[]\n",
    "    }\n",
    "    \n",
    "    paths = glob.glob(file_pattern)\n",
    "    \n",
    "    for path in paths:\n",
    "        window_size = path.split('/')[-1].split('_')[2]\n",
    "        horizan = path.split('/')[-1].split('_')[4]\n",
    "        stride = path.split('/')[-1].split('_')[6].split('.')[0]\n",
    "\n",
    "        df = pd.read_csv(path)\n",
    "        eval_dict['window_size'].append(window_size)\n",
    "        eval_dict['horizan'].append(horizan)\n",
    "        eval_dict['stride'].append(stride)\n",
    "\n",
    "        eval_dict['AVG_MAE'].append(df['MAE'].mean())\n",
    "        eval_dict['AVG_MSE'].append(df['MSE'].mean())\n",
    "        eval_dict['AVG_RMSE'].append(df['RMSE'].mean())\n",
    "        eval_dict['AVG_MAPE'].append(df['MAPE'].mean())\n",
    "        \n",
    "        eval_dict['AVG_SMAPE'].append(df['SMAPE'].mean())\n",
    "        eval_dict['AVG_R2'].append(df['R2'].mean())\n",
    "        eval_dict['AVG_MEDEA'].append(df['MEDEA'].mean())\n",
    "        eval_dict['AVG_MSLE'].append(df['MSLE'].mean())\n",
    "    \n",
    "    eval_df = pd.DataFrame.from_dict(eval_dict)\n",
    "    eval_df = eval_df.dropna()\n",
    "    eval_df.sort_values(['window_size', 'horizan', 'stride'], inplace=True, ascending=True)\n",
    "    \n",
    "    return eval_df\n",
    "\n",
    "# Example usage\n",
    "file_pattern = '../ProcessedData/Results/XGBMODEL/xgbmodel/*.csv'\n",
    "result_df = aggregate_evaluation_results(file_pattern)\n",
    "# result_df\n",
    "for name ,groupDf in result_df.groupby('window_size'):\n",
    "    display(groupDf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "darts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
