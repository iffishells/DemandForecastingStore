{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import darts\n",
    "from darts import TimeSeries\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import matplotlib.pyplot as plt\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import r2_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helping Functions \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_scatter(df):\n",
    "    os.makedirs('../plots',exist_ok=True)\n",
    "    saturday_Df = df[df['day_of_week']==5]\n",
    "    sunday_Df = df[df['day_of_week']==6]\n",
    "    friday_Df = df[df['day_of_week']==4]\n",
    "    thursday_Df = df[df['day_of_week']==3]\n",
    "    wednesday_Df = df[df['day_of_week']==2]\n",
    "    Tuesday_Df = df[df['day_of_week']==1]\n",
    "    monday_Df = df[df['day_of_week']==0]\n",
    "    fig = make_subplots()\n",
    "                        \n",
    "    \n",
    "    fig.add_trace(go.Scatter(x=df['date'], y=df['order_id'], mode='markers+lines',name='Quantity'),row=1,col=1)\n",
    "    fig.add_trace(go.Scatter(x=saturday_Df['date'], y=saturday_Df['order_id'], mode='markers',name='-Saturday-Quantity'),row=1,col=1)\n",
    "    fig.add_trace(go.Scatter(x=sunday_Df['date'], y=sunday_Df['order_id'], mode='markers',name='-Sunday-Quantity'),row=1,col=1)\n",
    "    fig.add_trace(go.Scatter(x=friday_Df['date'], y=friday_Df['order_id'], mode='markers',name='-friday-Quantity'),row=1,col=1)\n",
    "    fig.add_trace(go.Scatter(x=thursday_Df['date'], y=thursday_Df['order_id'], mode='markers',name='-Thursday-Quantity'),row=1,col=1)\n",
    "    fig.add_trace(go.Scatter(x=wednesday_Df['date'], y=wednesday_Df['order_id'], mode='markers',name='-Wednesday-Quantity'),row=1,col=1)\n",
    "    fig.add_trace(go.Scatter(x=Tuesday_Df['date'], y=Tuesday_Df['order_id'], mode='markers',name='-Tuesday-Quantity'),row=1,col=1)\n",
    "    fig.add_trace(go.Scatter(x=monday_Df['date'], y=monday_Df['order_id'], mode='markers',name='-Monday-Quantity'),row=1,col=1)\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='Scatter Plot of Order ID',\n",
    "        height=600,\n",
    "        width=1800,\n",
    "        font_size=14\n",
    "    )\n",
    "    fig.update_yaxes(title_text='Quantity', row=1, col=1)\n",
    "    fig.update_yaxes(title_text='Revenue', row=2, col=1)\n",
    "    fig.show()\n",
    "    # fig.write_html(f'../plots/{sku_id}_{region_id}.html')\n",
    "    \n",
    "def calculate_smape(actual, predicted):\n",
    "    \"\"\"\n",
    "    Calculate Symmetric Mean Absolute Percentage Error (SMAPE) given actual and predicted values.\n",
    "\n",
    "    Parameters:\n",
    "    actual (list or array): The actual (true) values.\n",
    "    predicted (list or array): The predicted values.\n",
    "\n",
    "    Returns:\n",
    "    smape (float): The SMAPE value.\n",
    "    \"\"\"\n",
    "    n = len(actual)\n",
    "    sum_smape = sum(2 * abs(a - p) / (abs(a) + abs(p)) for a, p in zip(actual, predicted))\n",
    "    smape = (1 / n) * sum_smape * 100\n",
    "    return smape\n",
    "\n",
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.metrics import mean_squared_log_error \n",
    "\n",
    "def calculate_metrics(actual, predicted):\n",
    "    # Convert inputs to numpy arrays for easier calculations\n",
    "    smape = calculate_smape(actual, predicted)\n",
    "    r2 = r2_score(actual, predicted)\n",
    "\n",
    "    medae = median_absolute_error(actual, predicted)\n",
    "\n",
    "    # Mean Squared Logarithmic Error (MSLE)\n",
    "    msle = mean_squared_log_error(actual, predicted)\n",
    "    \n",
    "    actual = np.array(actual)\n",
    "    predicted = np.array(predicted)\n",
    "    \n",
    "    # Calculate individual metrics\n",
    "    mae = np.mean(np.abs(predicted - actual))\n",
    "    rmse = np.sqrt(np.mean((predicted - actual) ** 2))\n",
    "    mape = np.mean(np.abs((predicted - actual) / actual)) * 100\n",
    "    mse = np.mean((predicted - actual) ** 2)\n",
    "    \n",
    "    metrics = {\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'MAPE': mape,\n",
    "        'MSE': mse,\n",
    "        'SMAPE':smape,\n",
    "        'R2':r2,\n",
    "        'MEDEA':medae,\n",
    "        'MSLE':msle,\n",
    "        \n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('../processedData/Iteration_03', exist_ok=True)\n",
    "\n",
    "fileName = '../RawData/Sales Forecast_NEW2.xlsx'\n",
    "df = pd.read_excel(fileName,sheet_name='NEW_DATA')\n",
    "df['date'] = pd.to_datetime(df['date'],format='%Y-%m-%d')\n",
    "df.sort_values(['date'],inplace=True)\n",
    "df.reset_index(inplace=True,drop=True)\n",
    "df.to_csv('../processedData/Iteration_03/sorted_Sales_Forecast_dataset.csv',index=False)\n",
    "df =  df[['date','order_id']]\n",
    "df.to_csv('../processedData/Iteration_03/date_order_sales_forecast_dataset.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.groupby('date')['order_id'].sum().reset_index()\n",
    "df.to_csv('../processedData/Iteration_03/date_order_id_sales_forecast_cleaned.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'] = df['date'].dt.year\n",
    "df['day_of_month'] = df['date'].dt.day\n",
    "df['month'] = df['date'].dt.month\n",
    "df['day_of_week'] = df['date'].dt.day_of_week\n",
    "df['day_name'] = df['date'].dt.strftime('%A')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stationary Tesst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adfuller_test(values):\n",
    "    result=adfuller(values)\n",
    "    labels = ['ADF Test Statistic','p-value','#Lags Used','Number of Observations Used']\n",
    "    for value,label in zip(result,labels):\n",
    "        print(label+' : '+str(value) )\n",
    "    if result[1] <= 0.05:\n",
    "        print(\"P value is less than 0.05 that means we can reject the null hypothesis(Ho). Therefore we can conclude that data has no unit root and is stationary\")\n",
    "    else:\n",
    "        print(\"Weak evidence against null hypothesis that means time series has a unit root which indicates that it is non-stationary \")\n",
    "adfuller_test(df['order_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spliting Data into Training & Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts import TimeSeries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming df is your DataFrame containing daily data\n",
    "series = TimeSeries.from_dataframe(df, \"date\", \"order_id\", freq='1D', fill_missing_dates=True, fillna_value=0)\n",
    "\n",
    "\n",
    "split_point = 0.80\n",
    "\n",
    "train_series, test_series = series.split_after(split_point)\n",
    "\n",
    "# Set the figure size and style\n",
    "plt.figure(figsize=(18, 6))\n",
    "# Plot the training and testing data\n",
    "train_series.plot(label='Training Data', color='blue', linewidth=1.5, marker='o')\n",
    "test_series.plot(label='Testing Data', color='orange', linewidth=1.5, marker='o')\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Training and Testing Data')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Sales')\n",
    "\n",
    "# Add grid lines\n",
    "plt.grid(True)\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts.utils.statistics import plot_acf, check_seasonality\n",
    "\n",
    "for m in range(2, 25):\n",
    "    is_seasonal, period = check_seasonality(train_series, m=m, alpha=0.05)\n",
    "    if is_seasonal:\n",
    "        print(\"There is seasonality of order {}.\".format(period))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto Correlation plot\n",
    "The autocorrelation function (ACF) is used to identify the order of ARIMA models. The ACF plot shows the correlation between the time series and its lagged version. The lag at which the ACF plot crosses the upper confidence interval for the first time is considered as the order of the **MA** component of the ARIMA model. Similarly, if the ACF plot decays slowly, it indicates that there is a high degree of autocorrelation in the time series, which means that an AR component should be included in the ARIMA model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts.utils.statistics import plot_acf,plot_pacf\n",
    "\n",
    "\n",
    "plot_acf(train_series, m=7, max_lag=100,  fig_size=(10, 5), axis=None, default_formatting=True)\n",
    "plt.xlabel('lags')\n",
    "plt.ylabel('correlation')\n",
    "plt.title('Auto Correlation Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partial Auto Correlation plot\n",
    "The partial autocorrelation function (PACF) is also used to identify the order of ARIMA models. The PACF plot shows the correlation between the time series and its lagged version, but with the influence of the intermediate lags removed. The lag at which the PACF plot crosses the upper confidence interval for the first time is considered as the order of the **AR** component of the ARIMA model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts.utils.statistics import plot_acf,plot_pacf\n",
    "plot_pacf(train_series, m=7, max_lag=100,  fig_size=(10, 5), axis=None, default_formatting=True)\n",
    "\n",
    "plt.xlabel('lags')\n",
    "plt.ylabel('correlation')\n",
    "plt.title('Partial Auto Correlation Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARIMA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts.dataprocessing.transformers.scaler import Scaler\n",
    "from darts.models.forecasting.arima import ARIMA\n",
    "\n",
    "arima_model = ARIMA(\n",
    "    p=4,\n",
    "    d=0, \n",
    "    q=2, \n",
    "    random_state=1999,\n",
    "    trend='n',\n",
    "    add_encoders={\n",
    "                'cyclic': {'future': ['month']},\n",
    "                'datetime_attribute': {'future': ['hour', 'dayofweek']},\n",
    "                'position': {'future': ['relative']},\n",
    "                'custom': {'future': [lambda idx: (idx.year - 1950) / 50]}\n",
    "            }\n",
    "                                            ,\n",
    ")\n",
    "\n",
    "arima_model.fit(train_series)\n",
    "arima_model.model.summary()\n",
    "\n",
    "arima_model.predict(3,series = test_series)\n",
    "\n",
    "horizan = 30*4\n",
    "\n",
    "# summary = arima_model.model.summary()\n",
    "test_series_ = test_series[0:horizan]\n",
    "plt.figure(figsize=(18, 6))\n",
    "forcast_arima = arima_model.predict(horizan)\n",
    "arima_model.predict(horizan).plot(marker='o',label='predicted')\n",
    "test_series_.plot(marker='o',label='Actual/Ground truth')\n",
    "# Add title and labels\n",
    "plt.title('Ground truth vs predicted')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Oder Number')\n",
    "plt.xticks(forcast_arima.time_index, forcast_arima.time_index.strftime('%Y-%m-%d'), rotation=90)\n",
    "\n",
    "# Add grid lines\n",
    "plt.grid(True)\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "arima_model.predict(3,series = test_series)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Function to predict and evaluate\n",
    "def predict_and_evaluate(window_size, prediction_horizon, slide_step, test_series, model,result_plot_path ):\n",
    "    num_predictions = len(test_series) - window_size - prediction_horizon + 1\n",
    "    \n",
    "    meta_information_evaluation = {\n",
    "        'Iterations': [],\n",
    "        'MAE': [],\n",
    "        'RMSE': [],\n",
    "        'MAPE': [],\n",
    "        'MSE': [],\n",
    "        'SMAPE':[],\n",
    "        'R2':[],\n",
    "        'MEDEA':[],\n",
    "        'MSLE':[],\n",
    "        'input_window_size': [],\n",
    "        'horizon': [],\n",
    "        'stride': []\n",
    "    }\n",
    "    try:\n",
    "        for i in tqdm(range(0, num_predictions, slide_step)):\n",
    "            input_window = test_series[i:i + window_size]\n",
    "            ground_truth = test_series[i + window_size:i + window_size + prediction_horizon]\n",
    "            forecast = model.predict(n=prediction_horizon, series=input_window)\n",
    "            actual = ground_truth.values().flatten().tolist()\n",
    "            \n",
    "            predicted = forecast.values().flatten().tolist()\n",
    "            metrics = calculate_metrics(actual, predicted)\n",
    "            \n",
    "            meta_information_evaluation['Iterations'].append(i)\n",
    "            meta_information_evaluation['MAE'].append(metrics['MAE'])\n",
    "            meta_information_evaluation['RMSE'].append(metrics['RMSE'])\n",
    "            meta_information_evaluation['MAPE'].append(metrics['MAPE'])\n",
    "            meta_information_evaluation['MSE'].append(metrics['MSE'])\n",
    "            meta_information_evaluation['input_window_size'].append(window_size)\n",
    "            meta_information_evaluation['horizon'].append(prediction_horizon)\n",
    "            meta_information_evaluation['stride'].append(slide_step)\n",
    "            \n",
    "            meta_information_evaluation['SMAPE'].append(metrics['SMAPE'])\n",
    "            meta_information_evaluation['R2'].append(metrics['R2'])\n",
    "            meta_information_evaluation['MEDEA'].append(metrics['MEDEA'])\n",
    "            meta_information_evaluation['MSLE'].append(metrics['MSLE'])\n",
    "        \n",
    "            bypass_information = {\n",
    "                'slide_step':slide_step,\n",
    "                'window_size':window_size,\n",
    "                'horizon':prediction_horizon,            \n",
    "            }\n",
    "            create_plots(input_window,forecast,ground_truth,result_plot_path,bypass_information)\n",
    "\n",
    "        evalaution_df = pd.DataFrame.from_dict(meta_information_evaluation)\n",
    "        \n",
    "        return evalaution_df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print('Error Occurred in fuction predict_and_evaluate():', e)\n",
    "        evalaution_df = pd.DataFrame.from_dict(meta_information_evaluation)\n",
    "        \n",
    "        return evalaution_df\n",
    "\n",
    "# Function to create plots\n",
    "def create_plots(input_window, forecast, ground_truth,result_plot_path,bypass_information):\n",
    "    plt.figure(figsize=(30, 6))\n",
    "    input_window.plot(label='Input Data', marker='o')\n",
    "    forecast.plot(label='Predicted', marker='o')\n",
    "    ground_truth.plot(label='Ground Truth', marker='o')\n",
    "    \n",
    "    combined_time_index = input_window.time_index.append(forecast.time_index).append(ground_truth.time_index)\n",
    "    starting_date_of_input_data = input_window.time_index[0].strftime(\"%Y-%m-%d\")\n",
    "    ending_date_of_input_data = input_window.time_index[-1].strftime(\"%Y-%m-%d\")\n",
    "    starting_date_predicted = forecast.time_index[0].strftime(\"%Y-%m-%d\")\n",
    "    ending_date_of_predicted = forecast.time_index[-1].strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    plt.xticks(combined_time_index, combined_time_index.strftime('%Y-%m-%d'), rotation=90)\n",
    "    plt.title(f'Results of Input Data from {starting_date_of_input_data} to {ending_date_of_input_data} & Evaluation on from {starting_date_predicted} to {ending_date_of_predicted}', fontsize=16)\n",
    "    plt.ylabel('Quantity Sold', fontsize=14)\n",
    "    plt.xlabel('Dates', fontsize=14)\n",
    "    plt.legend()\n",
    "    \n",
    "    plot_filename = f\"{result_plot_path}/{bypass_information['window_size']}_{bypass_information['horizon']}_{bypass_information['slide_step']}.png\"\n",
    "    plt.savefig(plot_filename)\n",
    "    plt.close()\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation(model_name,model_object,test_series,FileName):\n",
    "    \n",
    "    result_path = f'../ProcessedData/Results/{model_name}/{FileName}'\n",
    "    result_plot_path = f'../ProcessedData/Results/{model_name}/{FileName}/{model_name}_Plots'\n",
    "    os.makedirs(result_path,exist_ok=True)\n",
    "    os.makedirs(result_plot_path,exist_ok=True)\n",
    "\n",
    "        # Set your parameters\n",
    "    window_sizes = [30, 45, 90]\n",
    "    prediction_horizons = [15, 30,35]\n",
    "    slide_steps = [5, 10, 15]\n",
    "\n",
    "    test_series = test_series\n",
    "    model = model_object\n",
    "\n",
    "    for window_size in window_sizes:\n",
    "        for prediction_horizon in prediction_horizons:\n",
    "            for slide_step in slide_steps:\n",
    "                print(f'Iteration : Window size : {window_size} Horizan: {prediction_horizon}, Stride : {slide_step}')\n",
    "                evaluation_df = predict_and_evaluate(window_size, prediction_horizon, slide_step, test_series, model,result_plot_path)\n",
    "                evaluation_df.to_csv(f'{result_path}/window_size_{window_size}_horizon_{prediction_horizon}_stride_{slide_step}.csv', index=False)\n",
    "                \n",
    "                print(f'Window_size_{window_size}_prediction_horizon_{prediction_horizon}_slide_step_{slide_step} - Evaluation completed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_name = 'ARIMA'\n",
    "FileName = 'arima_model'\n",
    "model_object = arima_model\n",
    "test_series = test_series \n",
    "model_evaluation(model_name,model_object,test_series,FileName)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "darts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
